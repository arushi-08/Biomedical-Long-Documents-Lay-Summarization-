{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c564fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import os\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_device(\"cuda\")\n",
    "# else:\n",
    "#     torch.set_default_device(\"cpu\")\n",
    "model_type = 'gemma2b' # orca13b\n",
    "model_id = \"google/gemma-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"nlp/model/{model_type}\", device_map=\"cuda:1\", torch_dtype=torch.bfloat16)\n",
    "    \n",
    "os.environ['HF_TOKEN'] = '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'\n",
    "os.environ['HF_HOME'] = '/data_vault/hexai/huggingface/hub/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ['HF_TOKEN'], cache_dir=os.environ['HF_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7df812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = \"/data_vault/hexai/Biolaysum/biolaysumm2024_data/eLife_train.jsonl\"\n",
    "elife_train = pd.read_json(path_or_buf=data, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284521b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "orca_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    max_length = 13000,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02079e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
    "llm = HuggingFacePipeline(pipeline = orca_pipeline, model_kwargs = {'temperature':0.75})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt_template = \"\"\"\n",
    "                      Write a concise lay term summary of this chunk of text from a medical article.\n",
    "                      {text}\n",
    "                      \"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "system_prompt =  f\"Summarize in lay terms. For example\\n\\nArticle:{elife_train.loc[2529].article}\\nLay Summary:{elife_train.loc[2529].lay_summary}\" \n",
    "                     \n",
    "    \n",
    "combine_temp = \"\"\" \n",
    "                      Write a concise lay term summary of the following text delimited by triple backquotes.\n",
    "                      ```{text}```\n",
    "\n",
    "                      \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=system_prompt + combine_temp, input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6d6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    metadata[\"lay_summary\"] = record.get(\"lay_summary\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=\"/data_vault/hexai/Biolaysum/biolaysumm2024_data/eLife_train.jsonl\",\n",
    "    jq_schema='.',\n",
    "    content_key=\"article\",\n",
    "    metadata_func=metadata_func,\n",
    "    json_lines=True\n",
    ")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b6968bd-0544-4991-b01d-314637a7357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "map_template = \"\"\"Write a summary of the content below. Summarize 1.) Key ideas an 2.) Key findings using lay terms:\n",
    "\n",
    "{content}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_prompt_template)\n",
    "map_chain = LLMChain(prompt=map_prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c612c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "reduce_template = \"\"\"The following is set of summaries of a medical article:\n",
    "\n",
    "{doc_summaries}\n",
    "\n",
    "Summarize the above summaries. \n",
    "Summary:\"\"\"\n",
    "\n",
    "\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(prompt=reduce_prompt, llm=llm)\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bcb9294-30a8-4d94-8b33-d1ce14c6d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "reduce_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=stuff_chain,\n",
    "    token_max=8000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e845858d-62b5-4e7b-96c5-d2ffd971f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    document_variable_name=\"text\",\n",
    "    reduce_documents_chain=reduce_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6579908-7b6e-4dd8-bf09-3cb5b405b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[3830]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ecb100df-0bcf-4566-9b22-103aaf243cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=500)\n",
    "split_docs = splitter.split_documents([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "380ad78c-074d-4e49-84e1-790f7deac1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "530bdbe8-5d0a-4245-890c-53cb98ff9eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "415\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "for doc in split_docs:\n",
    "    print(len(doc.page_content.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d41e35c2-b405-4fab-8f2d-7f84151704c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngl18/anaconda3/envs/lora/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ngl18/anaconda3/envs/lora/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is set of summaries of a medical article:\n",
      "\n",
      "\n",
      "                      Write a concise lay term summary of this chunk of text from a medical article.\n",
      "                      Interoception , the sensitivity to visceral sensations , plays an important role in homeostasis and guiding motivated behaviour . It is also considered to be fundamental to self-awareness . Despite its importance , the developmental origins of interoceptive sensitivity remain unexplored . We here provide the first evidence for implicit , flexible interoceptive sensitivity in 5 month old infants using a novel behavioural measure , coupled with an established cortical index of interoceptive processing . These findings have important implications for the understanding of the early developmental stages of self-awareness , self-regulation and socio-emotional abilities . \n",
      " Forty-one healthy , full-term infants were tested in total , at 5 months of age ( 19 males , mean age = 5 . 10 months , SD = 0 . 29 ) . The expected effect sizes were not known in advance , so samples were selected according to similar adult literature ( e . g . [Fukushima et al . , 2011] ) assuming an approximate 50% attrition rate , which is usual in infant EEG studies with this age range . Infants were recruited using a marketing company database , which provides data information from consenting mothers to be . Recruitment leaflets were sent to each household . Parents were able to participate by signing up to our online database or by contacting us via email . The study was completed in one session , and conducted according to the Declaration of Helsinki and all methods were approved by the Royal Holloway University of London Departmental Ethics Committee . Mothers and infants familiarised themselves with the testing room . Infants first performed the iBEAT task . After a short break for feeding and changing if needed , they were then placed on their mother’s lap for the EEG cap and electrodes to be fitted . Once the EEG signal was clear and the infant was ready , they were returned to the high-chair and the Emotion Observation Task was run . The cap and ECG electrodes were then removed , and mother and infant were taken to a comfortable rest area to take a break , feed and change if necessary . The mother then completed a brief questionnaire and further behavioural task ( the results of which will be reported in a separate publication ) before being thanked , debriefed and given a small gift and monetary compensation for travel costs . All tests were evaluated against a two-tailed p<0 . 05 level of significance . For the HEP analysis , a Monte-Carlo random cluster-permutation method was implemented in FieldTrip . This\n",
      "                      method generated a number of random clusters of data points ( each cluster being represented by a set of electrode time-points ) and tested the difference between these clusters on a two-tailed p less than 0. 05 level with the help of a p-value that was obtained by shuffling the clusters and generating their p-values. In addition, a Monte Carlo test was implemented using a Random Walk in R package to generate random clusters of electrode times. These methods generated the p values that tested the difference between these clusters on a two-tailed p less than 0. 05.\n",
      "\n",
      "\n",
      "                      Write a concise lay term summary of this chunk of text from a medical article.\n",
      "                       and infants familiarised themselves with the testing room . Infants first performed the iBEAT task . After a short break for feeding and changing if needed , they were then placed on their mother’s lap for the EEG cap and electrodes to be fitted . Once the EEG signal was clear and the infant was ready , they were returned to the high-chair and the Emotion Observation Task was run . The cap and ECG electrodes were then removed , and mother and infant were taken to a comfortable rest area to take a break , feed and change if necessary . The mother then completed a brief questionnaire and further behavioural task ( the results of which will be reported in a separate publication ) before being thanked , debriefed and given a small gift and monetary compensation for travel costs . All tests were evaluated against a two-tailed p<0 . 05 level of significance . For the HEP analysis , a Monte-Carlo random cluster-permutation method was implemented in FieldTrip . This method corrects for multiple comparisons in space and time ( Maris and Oostenveld , 2007 ) . Using this method , all samples that showed a significant ( p< . 05 ) relationship with our independent variable were clustered according to spatiotemporal adjacencies , and cluster-level statistics were calculated by taking a sum of the t-values for each cluster . A Monte-Carlo permutation method then generated a p-value by calculating the probability that this cluster-level statistic could be achieved by chance , by randomly shuffling and resampling the independent variable structure a large number of times ( 2000 repetitions ) ( Maris and Oostenveld , 2007 ) . Spatiotemporal clusters that had a resulting Monte-Carlo corrected p-value of less than the critical alpha level of . 05 were interpreted as ‘significant’ . For both the iBEAT task and the HEP measurement , data collection was not performed blind to the experimental condition to which each trial belonged , due to the requirements for stimulus and cardiac monitoring during the task . However , for HEP analysis , experimental condition was removed from the data after data collection and all EEG pre-processing was performed blind to the conditions of the experiment . Condition was revealed at final statistical analysis so that specific emotions could be compared to the neutral condition . Both reported tasks had within-subjects designs involving no group allocation; therefore , blinding to any between-subject conditions and randomization to such\n",
      "                      within-subjects conditions was maintained.\n",
      "\n",
      "\n",
      "                      Write a concise lay term summary of this chunk of text from a medical article.\n",
      "                       could be achieved by chance , by randomly shuffling and resampling the independent variable structure a large number of times ( 2000 repetitions ) ( Maris and Oostenveld , 2007 ) . Spatiotemporal clusters that had a resulting Monte-Carlo corrected p-value of less than the critical alpha level of . 05 were interpreted as ‘significant’ . For both the iBEAT task and the HEP measurement , data collection was not performed blind to the experimental condition to which each trial belonged , due to the requirements for stimulus and cardiac monitoring during the task . However , for HEP analysis , experimental condition was removed from the data after data collection and all EEG pre-processing was performed blind to the conditions of the experiment . Condition was revealed at final statistical analysis so that specific emotions could be compared to the neutral condition . Both reported tasks had within-subjects designs involving no group allocation; therefore , blinding to any between-subject conditions and randomization to such conditions was not applicable .\n",
      "                      \n",
      "\n",
      "Summarize the above summaries. \n",
      "Summary:\n",
      "These summaries indicate that the iBEAT task and the HEP measurement were performed blind to the experimental condition to which each trial belonged, thus eliminating any between-subject comparisons or randomization to such conditions. The results are reported after they have been subjected to final statistical analysis, thus ensuring that no between-subject comparisons or randomization will affect the results.\n"
     ]
    }
   ],
   "source": [
    "summary = map_reduce_chain.run(split_docs)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da983c8-f857-4f3e-9a7e-ea4ed2773b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d72c3-3fd0-4c4f-915d-42bd1b1504a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
